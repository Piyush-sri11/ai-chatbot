import { AIModel, ProviderGroup } from "../types";

export const models: AIModel[] = [
  // OpenAI models
  {
    id: "gpt-4o",
    name: "GPT-4o",
    provider: "openai",
    description:
      "Most powerful model with multimodal capabilities, including vision and audio.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 32000,
    apiParam: "gpt-4o",
  },
  {
    id: "gpt-4o-mini",
    name: "GPT-4o Mini",
    provider: "openai",
    description: "Faster, cost-effective multimodal model for everyday use.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "gpt-4o-mini",
  },
  {
    id: "gpt-o1",
    name: "GPT-o1",
    provider: "openai",
    description: "Advanced flagship model for reasoning and generation.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "gpt-o1",
  },
  {
    id: "o1-mini",
    name: "o1 Mini",
    provider: "openai",
    description: "Lightweight version of o1 with solid performance.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "o1-mini",
  },
  {
    id: "o1-preview",
    name: "o1 Preview",
    provider: "openai",
    description: "Preview version of o1, includes experimental features.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "o1-preview",
  },
  {
    id: "gpt-4-turbo",
    name: "GPT-4 Turbo",
    provider: "openai",
    description: "High-performance GPT-4 variant with 128k context window.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "gpt-4-turbo",
  },
  {
    id: "gpt-4.5",
    name: "GPT-4.5 (Orion)",
    provider: "openai",
    description:
      "Enhanced reasoning, reduced hallucinations, and emotionally intelligent interactions.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "gpt-4.5",
  },
  {
    id: "o1-pro",
    name: "OpenAI o1 Pro",
    provider: "openai",
    description: "Pro version of o1 with deeper reasoning and higher compute.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "o1-pro",
  },
  {
    id: "o3-mini-high",
    name: "o3 Mini High",
    provider: "openai",
    description: "High-effort reasoning variant of o3 Mini.",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "o3-mini-high",
  },
  {
    id: "dalle-2",
    name: "DALL·E 2",
    provider: "openai",
    description: "Image generation model (earlier generation).",
    supportsImages: false,
    supportsFiles: false,
    maxTokens: 0,
    apiParam: "dall-e-2",
    isImageGenerator: true,
  },
  {
    id: "dalle-3",
    name: "DALL·E 3",
    provider: "openai",
    description:
      "Latest image generation model with better realism and detail.",
    supportsImages: false,
    supportsFiles: false,
    maxTokens: 0,
    apiParam: "dall-e-3",
    isImageGenerator: true,
  },
  {
    id: "sora",
    name: "Sora",
    provider: "openai",
    description:
      "Text-to-video generation model for creating short dynamic videos.",
    supportsImages: false,
    supportsFiles: true,
    maxTokens: 0,
    apiParam: "sora",
  },
  // Llama models
  {
    id: "llama-3-70b-chat",
    name: "Llama 3 70B",
    provider: "llama",
    description: "Meta's largest open model",
    supportsImages: false,
    supportsFiles: false,
    maxTokens: 4096,
    apiParam: "llama-3-70b-chat",
  },
  {
    id: "llama-3-8b-chat",
    name: "Llama 3 8B",
    provider: "llama",
    description: "Efficient and compact model",
    supportsImages: false,
    supportsFiles: false,
    maxTokens: 4096,
    apiParam: "llama-3-8b-chat",
  },
  // Gemini models
  {
    id: "gemini-1.5-pro",
    name: "Gemini 1.5 Pro",
    provider: "gemini",
    description: "Google's multimodal model",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 32768,
    apiParam: "gemini-1.5-pro",
  },
  {
    id: "gemini-1.5-flash",
    name: "Gemini 1.5 Flash",
    provider: "gemini",
    description: "Fast and efficient responses",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 32768,
    apiParam: "gemini-1.5-flash",
  },
  {
    id: "gemini-2-pro",
    name: "Gemini 2 Pro",
    provider: "gemini",
    description: "Latest Google model with document understanding",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 128000,
    apiParam: "gemini-2-pro",
  },
  // Claude models
  {
    id: "claude-3-opus",
    name: "Claude 3 Opus",
    provider: "claude",
    description: "Anthropic's most powerful model",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 200000,
    apiParam: "claude-3-opus",
  },
  {
    id: "claude-3-sonnet",
    name: "Claude 3 Sonnet",
    provider: "claude",
    description: "Balanced performance and efficiency",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 200000,
    apiParam: "claude-3-sonnet",
  },
  {
    id: "claude-3-haiku",
    name: "Claude 3 Haiku",
    provider: "claude",
    description: "Fast and efficient responses",
    supportsImages: true,
    supportsFiles: true,
    maxTokens: 200000,
    apiParam: "claude-3-haiku",
  },
];

export const getModelById = (id: string): AIModel | undefined => {
  return models.find((model) => model.id === id);
};

export const modelGroups: ProviderGroup[] = [
  {
    provider: "openai",
    label: "OpenAI",
    models: models.filter((model) => model.provider === "openai"),
  },
  {
    provider: "llama",
    label: "Llama",
    models: models.filter((model) => model.provider === "llama"),
  },
  {
    provider: "gemini",
    label: "Gemini",
    models: models.filter((model) => model.provider === "gemini"),
  },
  {
    provider: "claude",
    label: "Claude",
    models: models.filter((model) => model.provider === "claude"),
  },
];

export const defaultModelId = "gpt-4o-mini";
